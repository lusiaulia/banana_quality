{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyek Pertama ML Terapan\n",
    "- **Nama:** Lusi Aulia Jati\n",
    "- **Email:** lusiauliajati@gmail.com\n",
    "- **Sumber Data:** https://www.kaggle.com/datasets/l3llff/banana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Softness</th>\n",
       "      <th>HarvestTime</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.924968</td>\n",
       "      <td>0.468078</td>\n",
       "      <td>3.077832</td>\n",
       "      <td>-1.472177</td>\n",
       "      <td>0.294799</td>\n",
       "      <td>2.435570</td>\n",
       "      <td>0.271290</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.409751</td>\n",
       "      <td>0.486870</td>\n",
       "      <td>0.346921</td>\n",
       "      <td>-2.495099</td>\n",
       "      <td>-0.892213</td>\n",
       "      <td>2.067549</td>\n",
       "      <td>0.307325</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.357607</td>\n",
       "      <td>1.483176</td>\n",
       "      <td>1.568452</td>\n",
       "      <td>-2.645145</td>\n",
       "      <td>-0.647267</td>\n",
       "      <td>3.090643</td>\n",
       "      <td>1.427322</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.868524</td>\n",
       "      <td>1.566201</td>\n",
       "      <td>1.889605</td>\n",
       "      <td>-1.273761</td>\n",
       "      <td>-1.006278</td>\n",
       "      <td>1.873001</td>\n",
       "      <td>0.477862</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.651825</td>\n",
       "      <td>1.319199</td>\n",
       "      <td>-0.022459</td>\n",
       "      <td>-1.209709</td>\n",
       "      <td>-1.430692</td>\n",
       "      <td>1.078345</td>\n",
       "      <td>2.812442</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Size    Weight  Sweetness  Softness  HarvestTime  Ripeness   Acidity  \\\n",
       "0 -1.924968  0.468078   3.077832 -1.472177     0.294799  2.435570  0.271290   \n",
       "1 -2.409751  0.486870   0.346921 -2.495099    -0.892213  2.067549  0.307325   \n",
       "2 -0.357607  1.483176   1.568452 -2.645145    -0.647267  3.090643  1.427322   \n",
       "3 -0.868524  1.566201   1.889605 -1.273761    -1.006278  1.873001  0.477862   \n",
       "4  0.651825  1.319199  -0.022459 -1.209709    -1.430692  1.078345  2.812442   \n",
       "\n",
       "  Quality  \n",
       "0    Good  \n",
       "1    Good  \n",
       "2    Good  \n",
       "3    Good  \n",
       "4    Good  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# load the dataset\n",
    "bnn = pd.read_csv(\"./banana_quality.csv\")\n",
    "bnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melihat informasi jumlah dan jenis data \n",
    "bnn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melihat statistik deskriptif dari data\n",
    "bnn.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengecek apakah ada data kosong\n",
    "bnn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier dari data\n",
    "sns.boxplot(bnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = bnn.quantile(0.25)\n",
    "Q3 = bnn.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "bnn=bnn[~((bnn<(Q1-1.5*IQR))|(bnn>(Q3+1.5*IQR))).any(axis=1)]\n",
    " \n",
    "# Cek ukuran dataset setelah drop outliers\n",
    "bnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(bnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudah bersih dari outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "correlation_matrix = bnn.corr().round(2)\n",
    " \n",
    "# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True\n",
    "sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )\n",
    "plt.title(\"Correlation Matrix untuk Fitur Numerik \", size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(bnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan mneggunakan data waktu panen dan ukuran, apakah waktu panen berpengaruh pada ukuran buah pisang yang dipanen. Menggunakan model K-Nearest Neighbor (KNN), Random Forest, dan Boosting Algorithm. Akan digunakan data train 80% dan test 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "bnn = bnn.drop('Quality',)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "bnn_scaled = scaler.fit_transform(bnn)\n",
    " \n",
    "X = bnn_scaled[\"HarvestTime\"]\n",
    "y = bnn_scaled[\"Size\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total # of sample in whole dataset: {len(X)}')\n",
    "print(f'Total # of sample in train dataset: {len(X_train)}')\n",
    "print(f'Total # of sample in test dataset: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "bnn_scaled = scaler.fit_transform(df)\n",
    "\n",
    "total_dataset = len(df)\n",
    "df_train = df_scaled[:int(total_dataset*0.80)]\n",
    "df_test = df_scaled[int(total_dataset*0.80):total_dataset]\n",
    "\n",
    "print('Data for train:', df_train.shape)\n",
    "print('Total day for train:', round(df_train.shape[0]/24))\n",
    "print('\\nData for test:', df_test.shape)\n",
    "print('Total day for test:', round(df_test.shape[0]/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    " \n",
    "models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualising a Subset of our data - important features\n",
    "\n",
    "g = sns.pairplot(raw_data[['Visitors', 'Revenue', 'Marketing Spend', 'Day_Name']], hue = 'Day_Name', height = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising a Subset of our data - important features\n",
    "\n",
    "g = sns.lmplot(x = 'Marketing Spend', y = 'Revenue', data = raw_data, col = 'Day_Name', col_wrap = 3, height = 5, \n",
    "              scatter_kws = {'color':'green'}, ci = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the distribution of Revenue by Categorical Variables\n",
    "\n",
    "pal = ['green', 'blue','red']\n",
    "\n",
    "g = sns.boxplot(x = 'Day_Name', y = 'Revenue', data = raw_data, hue = 'Promo', palette = pal)\n",
    "               \n",
    "#ax = sns.swarmplot(x = 'Day_Name', y = 'Revenue', data = raw_data, palette = pal, hue = 'Promo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting outliers\n",
    "\n",
    "raw_data = raw_data[raw_data['Revenue'] < 27000]\n",
    "\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting usefull columns only\n",
    "raw_data = raw_data[['Day_Name','Visitors', 'Revenue', 'Marketing Spend', 'Promo']]\n",
    "\n",
    "#visualize the raw data\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making categorical variables into numeric representation\n",
    "\n",
    "new_raw_data = pd.get_dummies(raw_data, columns = ['Promo', 'Day_Name'])\n",
    "\n",
    "# Notes:\n",
    "# We can also do this with Label Encoding and OneHotEncoder from the preprocessing library\n",
    "\n",
    "# Visualizing the data\n",
    "new_raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Feature Selection\n",
    "\n",
    "In this example, we do not have many variables so we should use all of the data but in some cases, you have thousands of variables and you will need to filter them in order to save computational time\n",
    "\n",
    "- 2 ways to help us select the important features are:\n",
    "    - Correlation \n",
    "    - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Correlation\n",
    "\n",
    "hm = new_raw_data[['Visitors','Revenue','Marketing Spend']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "- .corr() is used to find the pairwise correlation of all columns in the dataframe. Any null values are automatically excluded\n",
    "- The closer to 1 or -1 the better. As one variable increases, the other variable tends to also increase / decrease\n",
    "- 0.8 +- is Strong Correlation, 0.6 to 0.8 +- is moderate Correlation & the other values, there is no correlation\n",
    "- More Info here: https://statisticsbyjim.com/basics/correlations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Correlation with a Heatmap\n",
    "\n",
    "g = sns.heatmap(hm, annot = True, annot_kws={'size':50})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps of Running Feature Importance\n",
    "- Split the data into X & y\n",
    "- Run a Tree-based estimators (i.e. decision trees & random forests) \n",
    "- Run Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X & y\n",
    "\n",
    "X = new_raw_data.drop('Revenue', axis = 1).values\n",
    "X2 = new_raw_data.drop('Revenue', axis = 1)\n",
    "y = new_raw_data['Revenue']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a Tree-based estimators (i.e. decision trees & random forests)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=15, criterion  = 'entropy', max_depth = 10)\n",
    "dt.fit(X,y)\n",
    "\n",
    "# If you want to learn how Decesion Trees work, read here: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "# Official Doc: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- The importance of a feature is calculated as the (normalized) total reduction of entropy (other criterions too) brought by that feature or the higher information gain\n",
    "- To understand the maths, read this: https://towardsdatascience.com/the-mathematics-of-decision-trees-random-forest-and-feature-importance-in-scikit-learn-and-spark-f2861df67e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Feature Importance\n",
    "\n",
    "for i, column in enumerate(new_raw_data.drop('Revenue', axis = 1)):\n",
    "    print('The feature importance for {} is: {:.3f}'.format(column, dt.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- Please note that we have not normalised / scale our data\n",
    "- Please note that we have not done any feature engineering - created new features\n",
    "- Please note that we have not joined multiple datasets together\n",
    "- Please note that we have not aggregated any of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Splitting the Raw Data - Hold-out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold-out validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size = 0.2, random_state=15)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Official Doc: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What is Linear Regression Analysis\n",
    "\n",
    "- Linear regression is a widely used machine learning model that predicts continues numbers as outputs; not classes \n",
    "- It models the relationship of 2 plus variables by fitting a linear equation to observed data \n",
    "- In linear regression you have 1 dependent variable (y) and 1 plus independent variables (X)\n",
    "- Before you attempt to model the data, you should check if there is a relationship between the variables first; a good way is to use a scatterplot to visualise the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graphical Anscombe's_quartet\n",
    "\n",
    "PATH = \"F:\\\\Github\\\\Python tutorials\\\\Introduction to ML - LR model\\\\\"\n",
    "Image(filename = PATH + \"Anscombe's_quartet.png\", width=900, height=900)\n",
    "\n",
    "\n",
    "# identical descriptive statistics\n",
    "# identical mean, std, variances, correlations, and regression lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Linear Regression Analysis (continued)\n",
    "\n",
    "- A measurement of the relationship between 2 variables is the correlation coefficient; ranging from -1 to 1; the closer to 1 or -1, the stronger the relationship\n",
    "\n",
    "- However, even if there seems to be a relationship, you should always be careful when modelling the relationship between 2 variables as correlation is not causation. For example, the rise of temperature vs Revenue\n",
    "\n",
    "- The mathematical equation of linear regression is Y = a + bX; where X is the independent variable and Y is the dependent variable. ‘b’ is the slope of the line and 'a' is the intercept; the value of y when x = 0\n",
    "\n",
    "\n",
    "- The most common cost function used in linear regression is the “Least Squared Errors” function; which is the sum of squared errors (sum(y actuals – y predicted) ^ 2) over the training set; trying to minimize how far off the predictions are from the actuals.\n",
    "\n",
    "- To calculate the “Least Squared Errors” firstly you must calculate the difference of the actual (y) vs the p(y); this is called the residuals.\n",
    "\n",
    "- In order to find the least squared error you will have to find the optimal parameter values (b) that minimize the sum ‘S’ of squared residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How L Regression iterates until convergence\n",
    "\n",
    "PATH = \"F:\\\\Github\\\\Python tutorials\\\\Introduction to ML - LR model\\\\\"\n",
    "Image(filename = PATH + \"Regression Example.png\", width=900, height=900)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Linear Regression Analysis (continued)\n",
    "\n",
    "- The optimisation technique used in linear regression is Gradient Descent; which attempts to find a local or a global minimum of a cost function\n",
    "\n",
    "- Gradient descent finds the direction ‘gradient’ that the model/line should take so that the errors will be reduced. \n",
    "\n",
    "- Direction refers to the weights (a and b), and how those weights should be tweaked to further reduce the errors. \n",
    "\n",
    "- The model will iterate until converged; no further improvements can be done; see graph below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "\n",
    "PATH = \"F:\\\\Github\\\\Python tutorials\\\\Introduction to ML - LR model\\\\\"\n",
    "Image(filename = PATH + \"Gradient Descent.png\", width=900, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Running Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Regression\n",
    "\n",
    "lm = LinearRegression(fit_intercept = True)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lm.predict(X_train)\n",
    "# SK-Learn official doc: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy on training dataset\n",
    "\n",
    "print('The Accuracy  on the training dataset is: ', lm.score(X_train, y_train) )\n",
    "print('The Accuracy n2  on the training dataset is: ',r2_score(y_train,y_pred) )   \n",
    "\n",
    "print(\"\")\n",
    "# Model Accuracy on testing dataset\n",
    "print('The Accuracy  on the testing dataset is: ', lm.score(X_test, y_test) )\n",
    "\n",
    "print(\"\")\n",
    "# The Root Mean Squared Error (RMSE)\n",
    "print('The RMSE  on the training dataset is: ',sqrt(mean_squared_error(y_train,y_pred)))\n",
    "print('The RMSE  on the testing dataset is: ',sqrt(mean_squared_error(y_test,lm.predict(X_test))))\n",
    "\n",
    "print(\"\")\n",
    "# The Mean Absolute Error (MAE)\n",
    "print('The MAE  on the training dataset is: ',mean_absolute_error(y_train,y_pred))\n",
    "print('The MAE  on the testing dataset is: ',mean_absolute_error(y_test,lm.predict(X_test)))\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "# Coefficients\n",
    "print('Coefficients: ', lm.coef_ )\n",
    "\n",
    "print(\"\")\n",
    "# The Intercept\n",
    "print('Intercept: ', lm.intercept_)\n",
    "\n",
    "\n",
    "# R2 Link: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "# RMSE Link: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "# MAE Link: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "    \n",
    "- The accuracy score represents the coefficient of determination ( 𝑅2 ). This is at max 1, but can be negative. It will be 0 if you predict the mean of y for all observations.\n",
    "\n",
    "- The R Square is measure of how close the data are to the fitted regression line. \n",
    "\n",
    "- In this case we can say that our model explains 79% of the training data & 75% of the testing data\n",
    "\n",
    "\n",
    "- The RMSE is the standard deviation of the residuals. Residuals is the difference between the predicted value and the  regression line. Hence RMSE is a measure of how spread your residuals are.\n",
    "\n",
    "- The mean absolute error (MAE) is the average of all the absolute errors. The absolute error is the difference between the true value (y_train) and the predicted value (y_pred).\n",
    "\n",
    "- Coeff are the weights\n",
    "\n",
    "- The intercept is the expected mean value of Y when all X=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Actuals Vs Predicted\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.scatter(y_train, y_pred, c='green')\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', c='red', lw=3)\n",
    "plt.xlabel('Actuals')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actuals Vs Predicted Values')\n",
    "# increase size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting Residuals\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.residplot(y_train, y_pred, color='green')\n",
    "plt.xlabel('Actual Revenue')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Actuals Vs Residuals')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next step should be to go back, remove more outliers and check if our model can be improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. How to use our L. Regression model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing Coeff into a table\n",
    "\n",
    "Coeff = lm.coef_\n",
    "Coeff.shape\n",
    "\n",
    "# Reshaping\n",
    "Coeff = Coeff.reshape(-1,12)\n",
    "\n",
    "\n",
    "# Creating a Dataframe\n",
    "Coeff_df = pd.DataFrame(Coeff, columns = [X2.columns])\n",
    "\n",
    "# Displaying \n",
    "Coeff_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
